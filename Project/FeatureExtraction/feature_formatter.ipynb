{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9afc3c4",
   "metadata": {},
   "source": [
    "# 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d148dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "RAND_STATE_GLOB = 1291\n",
    "\n",
    "import cv2\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import savetxt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import joblib\n",
    "import inspect\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "abspathdir = os.path.abspath(inspect.getfile(inspect.currentframe()))\n",
    "currentdir = os.path.dirname(abspathdir)\n",
    "parentdir  = os.path.dirname(currentdir)\n",
    "sys.path.insert(0, parentdir) \n",
    "\n",
    "from Utils._fe_utils import get_id\n",
    "\n",
    "import librosa as librosa\n",
    "import librosa.display as display\n",
    "\n",
    "import IPython.display as ipd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Deep Learning (Keras Setups)\n",
    "from keras.utils  import Sequence\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, BatchNormalization\n",
    "from keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, Dropout, SpatialDropout2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.losses import mse\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc35545",
   "metadata": {},
   "source": [
    "#### ii. Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24166341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sampleRate(audio_database):\n",
    "    v = list(audio_database.values())[0]\n",
    "    return v[\"SampleRate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282f009",
   "metadata": {},
   "source": [
    "### 1.1 Load semi-structured features from database file (mgbd.pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d4c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = currentdir + '/tmpdata'\n",
    "dbname = \"/mgdb.pkl\"\n",
    "db = joblib.load(db_dir + dbname)\n",
    "\n",
    "# Extract the video data (a nested database within the mgdb)\n",
    "video_db = db[\"Video\"]\n",
    "\n",
    "# Extract the audio data\n",
    "audio_db = db[\"Audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd3f4cd",
   "metadata": {},
   "source": [
    "#### 1.1.1 Perform some filtering on the databases and simplify the datastructures  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e898c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_db_simple = {}\n",
    "for k, v in video_db.items():\n",
    "    new_entry = {}\n",
    "    old_entry = video_db[k]\n",
    "    \n",
    "    # Remove a sample if the duration is less than 4 (secs)\n",
    "    duration = int(old_entry[\"Duration\"])\n",
    "    if duration < 4:\n",
    "        continue\n",
    "    \n",
    "    new_entry[\"MusicID\"] = old_entry[\"MetaInfo\"][\"MusicID\"]\n",
    "    new_entry[\"MusicEncoding\"] = old_entry[\"MusicEncoding\"]\n",
    "    new_entry[\"MotiongramX\"] = old_entry[\"MotiongramX\"]\n",
    "    new_entry[\"MotiongramY\"] = old_entry[\"MotiongramY\"]\n",
    "    \n",
    "    video_db_simple[k] = new_entry\n",
    "\n",
    "audio_db_simple = {}\n",
    "for k, v in audio_db.items():\n",
    "    old_entry = audio_db[k]\n",
    "    \n",
    "    # Remove a sample if the duration is less than 4 (secs)\n",
    "    duration = int(old_entry[\"Duration\"])\n",
    "    if duration < 4:\n",
    "        continue    \n",
    "    \n",
    "    audio_db_simple[old_entry[\"MusicID\"]] = old_entry[\"RawAudio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d15d2b6",
   "metadata": {},
   "source": [
    "#### 1.1.2 Convert the simplified dictionaries to pandas dataframes for easier access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900a0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dictionaries to pandas dataframes for easier access\n",
    "video_df = pd.DataFrame(video_db_simple)\n",
    "audio_df = pd.DataFrame(audio_db_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2aa763",
   "metadata": {},
   "source": [
    "# 2. Feature Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f886a79",
   "metadata": {},
   "source": [
    "#### 2.1 Setup class for handling spectrogram generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dc9b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramGenerator:\n",
    "    \n",
    "    def __init__(self, audio_df, sr, fmin, fmax, n_fft, hop_length, n_bins):\n",
    "        self.sr = sr\n",
    "        self.fmin = fmin\n",
    "        self.fmax = fmax\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length\n",
    "        self.n_bins = n_bins\n",
    "        \n",
    "        self.audio_df = audio_df\n",
    "        self.existing_spectros = {} \n",
    "        \n",
    "    def get_spectrogram(self, music_id):\n",
    "        if music_id in self.existing_spectros:\n",
    "            return self.existing_spectros[music_id]\n",
    "        \n",
    "        y = self.audio_df[music_id].to_numpy(dtype=np.float32)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(\n",
    "            y, n_mels=self.n_bins, sr=self.sr, \n",
    "            n_fft=self.n_fft, hop_length=self.hop_length, \n",
    "            window=scipy.signal.hamming,\n",
    "            fmin=self.fmin, fmax=self.fmax\n",
    "        )\n",
    "        mel_db = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "        self.existing_spectros[music_id] = mel_db\n",
    "        return mel_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1349fb7",
   "metadata": {},
   "source": [
    "#### 2.2 Setup a class for generating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d529247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, input_ids, input_df, target_generator, batch_size=32, \n",
    "             dim=(128, 128), n_channels=1, shuffle=True, flatten=True):\n",
    "        '''Initialization'''\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.input_ids = input_ids\n",
    "        self.input_df = input_df\n",
    "        self.target_generator = target_generator\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.flatten = flatten\n",
    "        self.on_epoch_end()        \n",
    "    \n",
    "    def __len__(self):\n",
    "        '''Denotes number of batches per epoch'''\n",
    "        return int(np.floor(len(self.input_ids) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index): \n",
    "        '''Generate one batch of data'''\n",
    "        # Generate idexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        # Find list of ids\n",
    "        input_ids_temp = [self.input_ids[k] for k in indexes]\n",
    "        \n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(input_ids_temp)\n",
    "        return (X, y)\n",
    "        \n",
    "    def __data_generation(self, input_ids_temp):\n",
    "        '''Generates data containing batch_size samples'''\n",
    "        # Initialization\n",
    "        if self.flatten == True:\n",
    "            X = np.empty((self.batch_size, self.dim[0] * self.dim[1]))\n",
    "            y = np.empty((self.batch_size, self.dim[0] * self.dim[1]))\n",
    "        else:\n",
    "            X = np.empty((self.batch_size, *self.dim))\n",
    "            y = np.empty((self.batch_size, *self.dim))\n",
    "        \n",
    "        # Generate data\n",
    "        for i, id_ in enumerate(input_ids_temp):\n",
    "            # Fetch example from the input dataframe\n",
    "            example = self.input_df[id_]\n",
    "            \n",
    "            # Get the motiogram\n",
    "            mgy = example[\"MotiongramY\"]\n",
    "            mgy = cv2.cvtColor(mgy, cv2.COLOR_RGB2GRAY)\n",
    "            mgy = cv2.resize(mgy, self.dim)\n",
    "            mgy = mgy.astype(np.float32)\n",
    "            mgy = mgy / 255.\n",
    "            X[i,] = mgy.flatten() #np.expand_dims(mgy, axis=-1)\n",
    "            \n",
    "            # Fetch the spectrogram\n",
    "            mel = self.target_generator.get_spectrogram(\n",
    "                example[\"MusicID\"]\n",
    "            )\n",
    "            y[i,] = mel.flatten() #np.expand_dims(mel, axis=-1)\n",
    "            return X, y\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        '''Updates indexes after each epoch'''\n",
    "        self.indexes = np.arange(len(self.input_ids))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b2977",
   "metadata": {},
   "source": [
    "# 3. Model Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa07e0c",
   "metadata": {},
   "source": [
    "#### 3.1 Setup a class that delivers a ML Model (CVAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b56f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalVariationalAutoEncoder:\n",
    "    \n",
    "    def __init__(self, input_dims, latent_dim, lr):\n",
    "        self.input_dims = input_dims\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr         = lr        \n",
    "        self.kernel     = (3,3)  \n",
    "        self.act_layer  = LeakyReLU()\n",
    "        self.optimizer  = optimizers.adam(lr=self.lr)\n",
    "        self.loss       = 'mse'\n",
    "        self.act_last_layer = 'sigmoid'\n",
    "        \n",
    "        self._make_encoder()\n",
    "        self._make_decoder()\n",
    "        self._make_VAE()\n",
    "    \n",
    "    def get_full_model(self):\n",
    "        return self.full_vae\n",
    "    \n",
    "    def get_encoder(self):\n",
    "        return self.encoder_vae\n",
    "    \n",
    "    def get_decoder(self):\n",
    "        return self.decoder_vae\n",
    "    \n",
    "    def _make_encoder(self):\n",
    "        '''Creates a field in the class representing the encoder model'''\n",
    "        \n",
    "        # Setup the input layer\n",
    "        input_dim_sca = self.input_dims[0] * self.input_dims[1]\n",
    "        self.input_encoder = Input(shape=(input_dim_sca,), name='input_encoder')\n",
    "        \n",
    "        # Setup hidden layers (Convolutional Layers)\n",
    "        encoder     = Reshape((self.input_dims[0], self.input_dims[1],-1))(self.input_encoder)\n",
    "        encoder     = Conv2D(32, self.kernel, activation=self.act_layer, padding='same')(encoder)\n",
    "        encoder     = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "        encoder     = Conv2D(64, self.kernel, activation=self.act_layer, padding='same')(encoder)\n",
    "        encoder     = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "        encoder     = Conv2D(128, self.kernel, activation=self.act_layer, padding='same')(encoder)\n",
    "        encoder     = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "        encoder     = Conv2D(256, self.kernel, activation=self.act_layer, padding='same')(encoder)\n",
    "        encoder     = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "        encoder     = Conv2D(512, self.kernel, activation=self.act_layer, padding='same')(encoder)\n",
    "        encoder     = MaxPooling2D((2, 2), padding='same')(encoder)\n",
    "        encoder     = Conv2D(1024, self.kernel, activation=self.act_layer, padding='same')(encoder)\n",
    "        encoder     = MaxPooling2D((4, 4), padding='same')(encoder)\n",
    "        encoder     = Flatten()(encoder)\n",
    "\n",
    "        # Setup special layers required for a VAE\n",
    "        self.z_mean    = Dense(self.latent_dim, name='z_mean')(encoder)\n",
    "        self.z_log_var = Dense(self.latent_dim, name='z_log_var')(encoder)  \n",
    "        self.z         = Lambda(ConvolutionalVariationalAutoEncoder.sampling, \n",
    "                        output_shape=(self.latent_dim,), name='z')([self.z_mean, self.z_log_var])\n",
    "        \n",
    "        # Full encoder model\n",
    "        self.encoder_vae = Model(self.input_encoder, \n",
    "                 [self.z_mean, self.z_log_var, self.z], name='encoder_vae')\n",
    "    \n",
    "    def _make_decoder(self):\n",
    "        # Setup the \"input\" layer for the decoder\n",
    "        input_dim_sca = self.input_dims[0] * self.input_dims[1]\n",
    "        input_latent = Input(shape=(self.latent_dim,), name='z_sampling')\n",
    "        \n",
    "        # Setup hidden layers (fully connected dense layers)\n",
    "        decoder = Dense(input_dim_sca//32, activation=self.act_layer)(input_latent)\n",
    "        decoder = Dense(input_dim_sca//8, activation=self.act_layer)(decoder)\n",
    "        decoder = Dense(input_dim_sca//4, activation=self.act_layer)(decoder)\n",
    "        decoder = Dense(input_dim_sca, activation=self.act_last_layer)(decoder)\n",
    "        \n",
    "        # Full decoder model\n",
    "        self.decoder_vae = Model(input_latent, decoder, name='decoder_vae')\n",
    "    \n",
    "    def _make_VAE(self):\n",
    "        '''Creates a full Variational AutoEncoder model'''\n",
    "        # Create the \"output\" layer (in this case our decoder model)\n",
    "        output_decoder = self.decoder_vae(\n",
    "            self.encoder_vae(self.input_encoder)[2])\n",
    "                \n",
    "        # Create the full model\n",
    "        self.full_vae = Model(\n",
    "            self.input_encoder, output_decoder, name='full_vae')\n",
    "        \n",
    "        # Setup special loss\n",
    "        input_dim_sca        = self.input_dims[0] * self.input_dims[1]\n",
    "        reconstruction_loss  = mse(self.input_encoder, output_decoder)\n",
    "        reconstruction_loss *= input_dim_sca \n",
    "        \n",
    "        #self.full_vae.add_loss(vae_loss)\n",
    "        self.full_vae.compile(optimizer=self.optimizer, \n",
    "                  loss=self.vae_loss_carrier(reconstruction_loss))\n",
    "    \n",
    "    def vae_loss_carrier(self, reconstruction_loss):\n",
    "        def vae_loss_fn(y_true, y_pred):\n",
    "            kl_loss  = 1 + self.z_log_var - K.square(self.z_mean) - K.exp(self.z_log_var)\n",
    "            kl_loss  = K.sum(kl_loss, axis=-1)\n",
    "            kl_loss *= -0.5\n",
    "            vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "            return vae_loss\n",
    "        return vae_loss_fn\n",
    "        \n",
    "    @staticmethod\n",
    "    def sampling(args):\n",
    "        '''Provides a method to sample from a normal distribution'''\n",
    "        z_mean, z_log_var = args\n",
    "        batch = K.shape(z_mean)[0]\n",
    "        dim = K.int_shape(z_mean)[1]\n",
    "        epsilon = K.random_normal(shape=(batch, dim))\n",
    "        return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cda8195",
   "metadata": {},
   "source": [
    "# 4. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab6e02",
   "metadata": {},
   "source": [
    "#### 4.1 Setup global variables for spectrogram generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling rate\n",
    "sr = get_sampleRate(audio_db)\n",
    "\n",
    "# min/max freq \n",
    "fmin, fmax = 20, sr / 2 \n",
    "\n",
    "# number of samples for each fft window. \n",
    "# for music it is recommended 2048, but with 4096 we are getting better results\n",
    "n_fft = 4096\n",
    "\n",
    "#(columns) - so we can get 128 frames \n",
    "hop_length = 690\n",
    "\n",
    "#(rows) - With this, we get nice 128 x 128 spectrograms \n",
    "n_mels = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf82635",
   "metadata": {},
   "source": [
    "##### 4.1.1 Instantiate an instance of the SpectrogramGenerator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f1df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_generator = SpectrogramGenerator(\n",
    "    audio_df=audio_df, sr=sr, \n",
    "    fmin=fmin, fmax=fmax, n_fft=n_fft,\n",
    "    hop_length=hop_length, n_bins=n_mels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6961566e",
   "metadata": {},
   "source": [
    "#### 4.2 Setup global variables for NN (hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6c1c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dims    = (128, 128)\n",
    "latent_dim    = 512\n",
    "batch_size    = 128\n",
    "epochs        = 1500\n",
    "learning_rate = 0.00025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e977c",
   "metadata": {},
   "source": [
    "#### 4.3 Setup KFolds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "RAND_STATE_GLOB = 1291\n",
    "\n",
    "# Create an instance of \"StratifiedKFold\" class\n",
    "# This class will perform the splits for us\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=4, shuffle=True, random_state=RAND_STATE_GLOB\n",
    ")\n",
    "\n",
    "# Create a list of integer labels on which the SKF can\n",
    "# perform its splits\n",
    "labels = list(video_df.loc[\"MusicEncoding\", :])\n",
    "\n",
    "# Create a dummy array to represent features.\n",
    "# We are only interested in the indexes provided\n",
    "dummy_features = np.zeros((len(video_df.columns), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19ad823",
   "metadata": {},
   "source": [
    "#### 4.4 Begin Actual Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe574a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An indexer to label the current fold\n",
    "fold_var = 1\n",
    "\n",
    "# Perform the K splits \n",
    "for train, test in skf.split(dummy_features, labels):\n",
    "    \n",
    "    # Print the samples in the test-train split\n",
    "    print(train.shape, test.shape)\n",
    "    \n",
    "    # Create our partition dictionary\n",
    "    partition = {\n",
    "        \"train\": list(video_df.columns[train]),\n",
    "        \"validation\": list(video_df.columns[test]) \n",
    "    }\n",
    "    \n",
    "    # Setup our data generators\n",
    "    training_generator = RegressionDataGenerator(\n",
    "        input_ids=partition[\"train\"], input_df=video_df, \n",
    "        target_generator=target_generator, batch_size=batch_size,\n",
    "        dim=input_dims, n_channels=1, shuffle=False\n",
    "    )\n",
    "    \n",
    "    validation_generator = RegressionDataGenerator(\n",
    "        input_ids=partition[\"validation\"], input_df=video_df, \n",
    "        target_generator=target_generator, batch_size=batch_size,\n",
    "        dim=input_dims, n_channels=1, shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Get an instance of the CVAE model\n",
    "    cvae  = ConvolutionalVariationalAutoEncoder(\n",
    "        input_dims, latent_dim, learning_rate)\n",
    "    model = cvae.get_full_model()\n",
    "        \n",
    "    # Train the model\n",
    "    model.fit_generator(\n",
    "        generator=training_generator,\n",
    "        steps_per_epoch=train.shape[0] // batch_size,\n",
    "        validation_data=validation_generator,\n",
    "        use_multiprocessing=True,\n",
    "        workers=6,\n",
    "        epochs=1,\n",
    "        verbose=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
